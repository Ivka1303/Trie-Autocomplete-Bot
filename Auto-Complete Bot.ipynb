{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Overview\n",
    "\n",
    "Auto-completion functionalities are now ubiquitous in search engines, document editors, and messaging apps. Here, I am developing an algorithmic strategy from scratch to implement these computational solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [trie tree](https://en.wikipedia.org/wiki/Trie), or a prefix tree, is a common data structure that stores a set of strings in a collection of nodes so that all strings with a common prefix are found in the same branch of the tree. Each node is associated with a letter, and as you traverse down the tree, you pick up more letters, eventually forming a word. Complete words are commonly found on the leaf nodes. However, some inner nodes can also mark full words.\n",
    "\n",
    "Let’s use an example diagram to illustrate several important features of tries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:15:24.668987Z",
     "start_time": "2022-02-21T11:15:24.664672Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kresh\\AppData\\Local\\Temp\\ipykernel_20608\\3475477571.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import Image, display\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://drive.google.com/uc?id=1NxHPsTzU3xEz2Ivck1NyqKpOix4Sc5iE\" width=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import Image, display\n",
    "display(Image(url='https://drive.google.com/uc?id=1NxHPsTzU3xEz2Ivck1NyqKpOix4Sc5iE', width=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few things to note from the schematics above:\n",
    "\n",
    "- Nodes that mark valid words are marked in yellow. Notice that while all leaves are considered valid words, only some inner nodes contain valid words, while some remain only prefixes to valid words appearing down the branch.\n",
    "\n",
    "- The tree does not have to be balanced, and the height of different branches depends on its contents.\n",
    "\n",
    "- In our implementation, branches never merge to show common suffixes (for example, both ANT and ART end in T, but these nodes are kept separate in their respective branches). However, this is a standard first line of memory optimization for tries.\n",
    "\n",
    "- The first node contains an empty string; it “holds the tree together.”"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python implementation of a trie tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical pondering\n",
    "<b> What is the better approach: making separate **Tree and Node** classes, or only making a **Node** class? </b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, it is more convenient to handle trees implemented using two classes. In this case, one will be able to handle unusual cases more efficiently. For example, if one had an empty tree and there are two separate classes for the tree and nodes, they could still use the methods set by the tree class. If there was only one class, it would get stuck because all the methods would have to work within the non-existent node.\n",
    "\n",
    "Besides, using two different classes, one can more easily dynamically create new nodes and insert them into the tree. Using only one class would be much less convenient because each time, they'd use the same one class that has a lot more methods embedded beside the assignment of the attributes. It would be harder to update the tree with new values using the old structure. Besides, having a separate class for the nodes allows us easily create nodes for multiple different trees."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    This class represents one node of a trie tree.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, char):\n",
    "        \n",
    "        #assigning value to the node and creating space for its kids\n",
    "        self.char = char\n",
    "        self.children = []\n",
    "        \n",
    "        #indicator of whether the character is the end of a valid word\n",
    "        self.is_end = False\n",
    "        \n",
    "        \n",
    "class Trie:\n",
    "    \"\"\"\n",
    "    This class represents the entirety of a trie tree.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    insert(self, word)\n",
    "        Inserts a word into the trie, creating nodes as required.\n",
    "    lookup(self, word)\n",
    "        Determines whether a given word is present in the trie.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, word_list = None):\n",
    "        \"\"\"\n",
    "        Creates the Trie instance, inserts initial words if provided.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word_list : list\n",
    "            List of strings to be inserted into the trie upon creation.\n",
    "        \"\"\"\n",
    "        \n",
    "        #setting root to an emty string        \n",
    "        self.root = Node(\"\")\n",
    "        \n",
    "        #converting all the words in the input list to lowercase \n",
    "        ##and inserting them into the tree\n",
    "        if word_list:\n",
    "            for word in word_list:\n",
    "                word = word.lower()\n",
    "                self.insert(word)\n",
    "        \n",
    "    \n",
    "    def insert(self, word):\n",
    "        \"\"\"\n",
    "        Inserts a word into the trie, creating missing nodes on the go.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be inserted into the trie.\n",
    "        \"\"\"\n",
    "        \n",
    "        #comparing the characters in the word with nodes starting from the root\n",
    "        node = self.root \n",
    "        \n",
    "        #looking for the characters in the tree\n",
    "        for char in word:\n",
    "            found_in_child = False\n",
    "            for child_node in node.children:\n",
    "                if child_node.char == char:\n",
    "                    node = child_node\n",
    "                    found_in_child = True\n",
    "        \n",
    "            #if the character is not in the tree yet placing it after the letters in the word \n",
    "            ##that are already present in the tree if any\n",
    "            if not found_in_child:\n",
    "                new_node = Node(char)\n",
    "                node.children.append(new_node)\n",
    "                node = new_node\n",
    "        \n",
    "        #marking the end of the word\n",
    "        node.is_end = True\n",
    "\n",
    "        \n",
    "    def lookup(self, word):\n",
    "        \"\"\"\n",
    "        Determines whether a given word is present in the trie.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be looked-up in the trie.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if the word is present in trie; False otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        node = self.root\n",
    "        \n",
    "        #if tree is empty returning False right away\n",
    "        if not node.children:\n",
    "            return False\n",
    "        \n",
    "        #converting the word we are looking for to lowercase as well\n",
    "        word = word.lower()\n",
    "            \n",
    "            \n",
    "        #looking for all the characters in the word that would be places consequently\n",
    "        for char in word:\n",
    "            char_not_found = True\n",
    "            for child in node.children:\n",
    "                if child.char == char:\n",
    "                    char_not_found = False\n",
    "                    node = child\n",
    "                    break\n",
    "        \n",
    "            if char_not_found:\n",
    "                return False\n",
    "        \n",
    "        #telling whether the full word is present in the tree\n",
    "        return node.is_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Namárië, JRRT's elvish poem written in Quenya\n",
    "wordbank = \"Ai! laurië lantar lassi súrinen, yéni unótimë ve rámar aldaron! \\\n",
    "Yéni ve lintë yuldar avánier mi oromardi lisse-miruvóreva Andúnë pella, \\\n",
    "Vardo tellumar nu luini yassen tintilar i eleni ómaryo airetári-lírinen. \\\n",
    "Sí man i yulma nin enquantuva? An sí Tintallë Varda Oiolossëo ve fanyar máryat Elentári ortanë, \\\n",
    "ar ilyë tier undulávë lumbulë; ar sindanóriello caita mornië i falmalinnar imbë met, \\\n",
    "ar hísië untúpa Calaciryo míri oialë. Sí vanwa ná, Rómello vanwa, Valimar! Namárië! \\\n",
    "Nai hiruvalyë Valimar. Nai elyë hiruva. \\\n",
    "Namárië!\".replace(\"!\", \"\").replace(\"?\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\";\", \"\").split()\n",
    "\n",
    "trie = Trie(wordbank)\n",
    "\n",
    "assert trie.lookup('oiolossëo') == True\n",
    "# this is a prefix, but also a word in itself\n",
    "assert trie.lookup('An') == True\n",
    "# this is a prefix, but NOT a word\n",
    "assert trie.lookup('ele') == False\n",
    "# not in the wordbank\n",
    "assert trie.lookup('Mithrandir') == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we see that the code easily finds English words present in the text regardless of whether they are lower or uppercase. I'll check how the code manages texts in different languages. I'm looking for the Ukrainian word \"Hello\" in Cyrillic. If it doesn't return any errors and just doesn't find it, we are all good. That would mean that different alphabets do not break the code.\n",
    "\n",
    "Also, I am checking the same property for numbers here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert trie.lookup('Привіт') == False\n",
    "assert trie.lookup('233') == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! As expected, the code doesn't return any errors and just doesn't find the numbers and words that are not present in the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, I am checking whether the code can really work with different alphabets. I input \"HeLlo, my family arrives on March 17th\" in Ukrainian. I am using both numbers and the Ukrainian language in the sentence to check how universal my program is. As we can see, it can indeed search and find numbers, words in different languages and with random uppercase letters, even the words that have special characters (word family \"сім'я\" in Ukrainian.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wordbank2 = \"Привіт, моя сім'я приїжджає 17 березня\".replace(\"!\", \"\").replace(\"?\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\";\", \"\").split()\n",
    "trie2 = Trie(wordbank2)\n",
    "\n",
    "assert trie2.lookup('ПриВіт') == True\n",
    "assert trie2.lookup(\"сім'я\") == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert trie2.lookup('17') == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the tests I could come up with on my own are passing. The only thing is that the user/customer should decide whether they want the code to detect words written in lowercase even though they were expected to be in uppercase. If they don't want to \"accept\" all the words, we should alter the code so it doesn't convert all the words to the lowercase. Instead, it returns an error if, for example, the word that is not right after a dot (a.k.a., is not at the beginning of the sentence) and starts with a capital letter/has any capital letters in it. But it is pretty complex since some words like names must always start with a capital letter. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The computational complexity of tries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The insert runtime for the trie tree depends on the length of the word we are inserting because we have to iterate through every letter, compare it to the existent nodes, and if the letter is not there yet, add it at the right spot. So, the complexity of insert() is O(N). \n",
    "\n",
    "Therefore, the average complexity of the trie tree constructions is N*L, where L is the average length of the words we are inserting, and N is the number of words. In the worst-case/best-case, L is constant for all words. Whether it is best or worst depends on the context. If the word is very long and we wish it was smaller because it would be easier to store, it is probably the worst-case scenario. \n",
    "\n",
    "lookup() has the same complexity of O(L) because to find the word, we are iterating through all the characters in the word again (using the for-loop) and comparing them to children on each level. The comparisons utilize for-loop as well; however, the number of children ranges a lot. We might have many nodes attached to one node having C = N-n, where n is the order of the parent node we are looking at. However, the remaining loops would not have that many nodes to look at. Eventually, it averages out back to O(L.) The best and worst-case scenarios are analogous to the ones in the insertion. \n",
    "\n",
    "BST stores comparable data, like numbers, because the placement of new nodes heavily depends on how larger/smaller is the new node as compared to the parent. In comparison, tries are only interested in whether the node is present within kids, and that's it. Because of that, it is tough to have a balanced trie. There must be nearly the same number of words with the same prefix. \n",
    "\n",
    "We can still adjust the BST, though, to make its keys be represented as strings. We could use the alphabetical order as the comparison variable in this case. Then potentially, we could create some sort of a dictionary BST, where each right child is located further in the alphabetical order than the left child as compared to the parent. \n",
    " \n",
    "Potentially BST would even be able to help us out with finding the words with the same prefixes. We'd have somehow to convert the string to its representation of alphabetical order and find the subtree that has this value as a parent. Some of the children of that node supposedly would have the same prefix. The insertion and search in BST with strings would be the same as for any other BST - O(h), where h is the tree's height. Since every node represents one word, the height would directly depend on the number of words and, on average, would equal nlogn. In the worst case, it would get up to O(n) if there's only one branch with the words. There would not be any different from the list of the evaluations of the alphabetical order of the given words. \n",
    "\n",
    "Since the complexity of operations in BST depends on the number of words but not their length, if we have a few very long words, BST might actually have a smaller runtime. \n",
    "\n",
    "\n",
    "However, if there are many words in the BST, there is a high probability that the children on lower levels connected to that parent would have different prefixes because they would get further in the alphabetical order. Trie tree guarantees us finding the words with a given prefix, though, so this data structure is valuable. There are no other data structures that would be able to support such operation (at least from the ones I can recall.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the $k$ most common words in a speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T11:39:21.831286Z",
     "start_time": "2022-02-21T11:39:21.827061Z"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    This class represents one node of a trie tree.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, char):\n",
    "        \n",
    "        self.char = char\n",
    "        self.children = []\n",
    "        self.is_end = False\n",
    "        \n",
    "        #counting how many times the word appeared\n",
    "        self.counter = 0\n",
    "        \n",
    "        \n",
    "class Trie:\n",
    "    \"\"\"\n",
    "    This class represents the entirety of a trie tree.\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    insert(self, word)\n",
    "        Inserts a word into the trie, creating nodes as required.\n",
    "    lookup(self, word)\n",
    "        Determines whether a given word is present in the trie.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, word_list = None):\n",
    "        \"\"\"Creates the Trie instance, inserts initial words if provided.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word_list : list\n",
    "            List of strings to be inserted into the trie upon creation.\n",
    "        \"\"\"\n",
    "           \n",
    "        self.root = Node(\"\")\n",
    "    \n",
    "        #creating a dict to track the words and the number of times they appeared\n",
    "        self.word_count = {}\n",
    "        \n",
    "        if word_list:\n",
    "            for word in word_list:\n",
    "                word = word.lower()\n",
    "                self.insert(word)\n",
    "        \n",
    "    \n",
    "    def insert(self, word):\n",
    "        \"\"\"\n",
    "        Inserts a word into the trie, creating missing nodes on the go.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be inserted into the trie.\n",
    "        \"\"\"\n",
    "        \n",
    "        node = self.root \n",
    "        \n",
    "        for char in word:\n",
    "            found_in_child = False\n",
    "            for child_node in node.children:\n",
    "                if child_node.char == char:\n",
    "                    node = child_node\n",
    "                    found_in_child = True\n",
    "        \n",
    "            if not found_in_child:\n",
    "                new_node = Node(char)\n",
    "                node.children.append(new_node)\n",
    "                node = new_node\n",
    "        \n",
    "        node.is_end = True\n",
    "        \n",
    "        #recording that the word appeared \n",
    "        node.counter += 1\n",
    "        \n",
    "        #updating the counter for the word\n",
    "        self.word_count[word] = node.counter\n",
    "\n",
    "        \n",
    "    def lookup(self, word):\n",
    "        \"\"\"\n",
    "        Determines whether a given word is present in the trie.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be looked-up in the trie.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if the word is present in trie; False otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        node = self.root\n",
    "        \n",
    "        if not node.children:\n",
    "            return False\n",
    "        \n",
    "        word = word.lower()\n",
    "            \n",
    "            \n",
    "        for char in word:\n",
    "            char_not_found = True\n",
    "            for child in node.children:\n",
    "                if child.char == char:\n",
    "                    char_not_found = False\n",
    "                    node = child\n",
    "                    break\n",
    "        \n",
    "            if char_not_found:\n",
    "                return False\n",
    "        \n",
    "        return node.is_end\n",
    "    \n",
    "    \n",
    "    def k_most_common(self, k):\n",
    "        \"\"\"\n",
    "        Finds k words inserted into the trie most often.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of most common words to be returned.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            List of tuples.\n",
    "            \n",
    "            Each tuple entry consists of the word and its frequency.\n",
    "            The entries are sorted by frequency.\n",
    "        \"\"\"\n",
    "        #sorting the words and counts alphabetically and then by the count values\n",
    "        sorted_count = {k: v for k, v in sorted(self.word_count.items(), key=lambda item: item[0])}\n",
    "        sorted_count = {k: v for k, v in sorted(sorted_count.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "        lst_common = []\n",
    "        \n",
    "        #picking k the most common words and returning the corresponding tuples\n",
    "        for key, value in sorted_count.items():\n",
    "            lst_common.append((key, value))\n",
    "            k -=1\n",
    "            if k == 0:\n",
    "                break\n",
    "        return lst_common\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, I am checking whether the code counts words right so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai': 1, 'laurië': 1, 'lantar': 1, 'lassi': 1, 'súrinen': 1, 'yéni': 2, 'unótimë': 1, 've': 3, 'rámar': 1, 'aldaron': 1, 'lintë': 1, 'yuldar': 1, 'avánier': 1, 'mi': 1, 'oromardi': 1, 'lisse-miruvóreva': 1, 'andúnë': 1, 'pella': 1, 'vardo': 1, 'tellumar': 1, 'nu': 1, 'luini': 1, 'yassen': 1, 'tintilar': 1, 'i': 3, 'eleni': 1, 'ómaryo': 1, 'airetári-lírinen': 1, 'sí': 3, 'man': 1, 'yulma': 1, 'nin': 1, 'enquantuva': 1, 'an': 1, 'tintallë': 1, 'varda': 1, 'oiolossëo': 1, 'fanyar': 1, 'máryat': 1, 'elentári': 1, 'ortanë': 1, 'ar': 3, 'ilyë': 1, 'tier': 1, 'undulávë': 1, 'lumbulë': 1, 'sindanóriello': 1, 'caita': 1, 'mornië': 1, 'falmalinnar': 1, 'imbë': 1, 'met': 1, 'hísië': 1, 'untúpa': 1, 'calaciryo': 1, 'míri': 1, 'oialë': 1, 'vanwa': 2, 'ná': 1, 'rómello': 1, 'valimar': 2, 'namárië': 2, 'nai': 2, 'hiruvalyë': 1, 'elyë': 1, 'hiruva': 1}\n"
     ]
    }
   ],
   "source": [
    "trie = Trie(wordbank)\n",
    "\n",
    "print(trie.word_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the words, so now I'll comу back to the code cell above and finish the sorting part and output k most common words. After adjustment, I am running the tests below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.0.1\n",
      "[notice] To update, run: C:\\Users\\kresh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\kresh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.28.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kresh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kresh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kresh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kresh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "\n",
    "from requests import get\n",
    "speakers = ['Faruqi', 'Kennedy', 'King', 'Thunberg', 'Havel']\n",
    "bad_chars = [';', ',', '.', '?', '!', '_', \n",
    "             '[', ']', ':', '“', '”', '\"', '–', '-']\n",
    "\n",
    "for speaker in speakers:\n",
    "    \n",
    "    # download and clean up the speech from extra characters\n",
    "    speech_full = get(f'https://bit.ly/CS110-{speaker}').text\n",
    "    just_text = ''.join(c for c in speech_full if c not in bad_chars)\n",
    "    without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in just_text)\n",
    "    just_words = [word for word in without_newlines.split(\" \") if word != \"\"]\n",
    "    \n",
    "    trie = Trie(just_words)\n",
    "    \n",
    "    if speaker == 'Faruqi':\n",
    "        Faruqi = [('the', 60), ('and', 45), ('to', 39), ('in', 37), \n",
    "                  ('of', 34), ('is', 25), ('that', 22), ('this', 21), \n",
    "                  ('a', 20), ('people', 20), ('has', 14), ('are', 13), \n",
    "                  ('for', 13), ('we', 13), ('have', 12), ('racism', 12), \n",
    "                  ('black', 11), ('justice', 9), ('lives', 9), ('police', 9)]\n",
    "        assert trie.k_most_common(20) == Faruqi\n",
    "    \n",
    "    elif speaker == 'Kennedy':\n",
    "        Kennedy = [('the', 117), ('and', 109), ('of', 93), ('to', 63), \n",
    "                   ('this', 44), ('in', 43), ('we', 43), ('a', 39), \n",
    "                   ('be', 30), ('for', 27), ('that', 27), ('as', 26), \n",
    "                   ('it', 24), ('will', 24), ('new', 22), ('space', 22), \n",
    "                   ('is', 21), ('all', 15), ('are', 15), ('have', 15), ('our', 15)]\n",
    "        assert trie.k_most_common(21) == Kennedy\n",
    "    \n",
    "    elif speaker == 'Havel':\n",
    "        Havel = [('the', 34), ('of', 23), ('and', 20), ('to', 15), \n",
    "                 ('in', 13), ('a', 12), ('that', 12), ('are', 9), \n",
    "                 ('we', 9), ('have', 8), ('human', 8), ('is', 8), \n",
    "                 ('you', 8), ('as', 7), ('for', 7), ('has', 7), ('this', 7), \n",
    "                 ('be', 6), ('it', 6), ('my', 6), ('our', 6), ('world', 6)]\n",
    "        assert trie.k_most_common(22) == Havel\n",
    "    \n",
    "    elif speaker == 'King':\n",
    "        King = [('the', 103), ('of', 99), ('to', 59), ('and', 54), ('a', 37), \n",
    "                ('be', 33), ('we', 29), ('will', 27), ('that', 24), ('is', 23), \n",
    "                ('in', 22), ('as', 20), ('freedom', 20), ('this', 20), \n",
    "                ('from', 18), ('have', 17), ('our', 17), ('with', 16), \n",
    "                ('i', 15), ('let', 13), ('negro', 13), ('not', 13), ('one', 13)]\n",
    "        assert trie.k_most_common(23) == King\n",
    "    \n",
    "    elif speaker == 'Thunberg':\n",
    "        Thunberg = [('you', 22), ('the', 20), ('and', 16), ('of', 15), \n",
    "                    ('to', 14), ('are', 10), ('is', 9), ('that', 9), \n",
    "                    ('be', 8), ('not', 7), ('with', 7), ('i', 6), \n",
    "                    ('in', 6), ('us', 6), ('a', 5), ('how', 5), ('on', 5), \n",
    "                    ('we', 5), ('all', 4), ('dare', 4), ('here', 4), \n",
    "                    ('my', 4), ('people', 4), ('will', 4)]\n",
    "        assert trie.k_most_common(24) == Thunberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll check this code using the text provided before. That one has more varied characters. Besides, since it is a lot smaller text we can read it ourselves and track any mistakes on the spot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = Trie(wordbank)\n",
    "\n",
    "assert trie.k_most_common(5) == [('ar', 3), ('i', 3), ('sí', 3), ('ve', 3), ('nai', 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, I'll popularize the Ukrainian language a bit more. Here I am uploading a text file with a Ukrainian novel \"Intermezzo\" by Mykhailo Kotsubynskyi. This is a novel about a guy who got tired of the hustle in the city and went to a village to relax. But he constantly has flashbacks about people back in the city he cares about and, after taking a bit of breath in the village, returns to the city to help and be three for others. Really cute and empowering. \n",
    "\n",
    "This text is another material to work with and see whether my code actually works. Besides, it can be used to prove that my code can work with multiple languages, a.k.a. it is quite universal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('і', 140), ('я', 86), ('на', 71), ('в', 70), ('як', 65)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('Intermezzo.txt', encoding=\"utf8\")\n",
    "text = file.read()\n",
    "text = text.replace(\"!\", \"\").replace(\"?\", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\";\", \"\").replace(\"-\", \"\").replace(\"*\", \"\").replace(\"—\", \"\").split()\n",
    "\n",
    "trie = Trie(text)\n",
    "trie.k_most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out the most popular word in that novel is \"and\" in Ukrainian, which is the \"i\" in the first tuple. The rest of the top most popular words are mostly prepositions \"on,\" \"in,\" and the pronounce \"I.\" This is very plausible because we constantly use these same words in combination with many others. For the third test, I'll look for more common words in that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('і', 140),\n",
       " ('я', 86),\n",
       " ('на', 71),\n",
       " ('в', 70),\n",
       " ('як', 65),\n",
       " ('що', 52),\n",
       " ('не', 51),\n",
       " ('й', 49),\n",
       " ('з', 45),\n",
       " ('у', 42),\n",
       " ('а', 40),\n",
       " ('мене', 37),\n",
       " ('ти', 33),\n",
       " ('так', 25),\n",
       " ('до', 21)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie.k_most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output in the code cell above contained characters such as * and —; therefore, I added them to the list of characters that must be removed before building the tree. The test helped me improve my code a tiny bit! The output above is plausible as well because it is just prepositions and pronouns:\n",
    "\n",
    "'і'    - 'and'         - 140,\n",
    "\n",
    "'я'    - 'I'            - 86,\n",
    "\n",
    "'на'   - 'on'           - 71,\n",
    "\n",
    "'в'    - 'in'           - 70,\n",
    "\n",
    "'як'   - 'as'           - 65,\n",
    "\n",
    "'що'   - 'that'         - 52,\n",
    "\n",
    "'не'   - 'not'          - 51,\n",
    "\n",
    "'й'    - 'and'          - 49,\n",
    "\n",
    "'з'    - 'with'         - 45,\n",
    "\n",
    "'у'    - 'in'/'next to' - 42,\n",
    "\n",
    "'а'    - 'and'/'but'    - 40,\n",
    "\n",
    "'мене' - 'me'           - 37,\n",
    "\n",
    "'ти'   - 'you'          - 33,\n",
    "\n",
    "'так'  - 'this way'     - 25,\n",
    "\n",
    "'до'   - 'to'           - 21\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing an autocomplete with a Shakespearean dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    This class represents one node of a trie tree.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, char):\n",
    "        \n",
    "        self.char = char\n",
    "        self.children = []\n",
    "        self.is_end = False\n",
    "        self.counter = 0\n",
    "        \n",
    "        \n",
    "class Trie:\n",
    "    \"\"\"\n",
    "    This class represents the entirety of a trie tree.\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    insert(self, word)\n",
    "        Inserts a word into the trie, creating nodes as required.\n",
    "    lookup(self, word)\n",
    "        Determines whether a given word is present in the trie.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, word_list = None):\n",
    "        \"\"\"\n",
    "        Creates the Trie instance, inserts initial words if provided.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word_list : list\n",
    "            List of strings to be inserted into the trie upon creation.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.root = Node(\"\")\n",
    "        self.word_count = {}\n",
    "        \n",
    "        if word_list:\n",
    "            for word in word_list:\n",
    "                word = word.lower()\n",
    "                self.insert(word)\n",
    "        \n",
    "    \n",
    "    def insert(self, word):\n",
    "        \"\"\"\n",
    "        Inserts a word into the trie, creating missing nodes on the go.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be inserted into the trie.\n",
    "        \"\"\"\n",
    "        \n",
    "        node = self.root \n",
    "        \n",
    "        for char in word:\n",
    "            found_in_child = False\n",
    "            for child_node in node.children:\n",
    "                if child_node.char == char:\n",
    "                    node = child_node\n",
    "                    found_in_child = True\n",
    "        \n",
    "            if not found_in_child:\n",
    "                new_node = Node(char)\n",
    "                node.children.append(new_node)\n",
    "                node = new_node\n",
    "\n",
    "        node.is_end = True\n",
    "        \n",
    "        node.counter += 1\n",
    "        \n",
    "        self.word_count[word] = node.counter\n",
    "\n",
    "        \n",
    "    def lookup(self, word):\n",
    "        \"\"\"\n",
    "        Determines whether a given word is present in the trie.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be looked-up in the trie.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if the word is present in trie; False otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        node = self.root\n",
    "        \n",
    "        if not node.children:\n",
    "            return False\n",
    "        \n",
    "        word = word.lower()\n",
    "            \n",
    "        for char in word:\n",
    "            char_not_found = True\n",
    "            for child in node.children:\n",
    "                if child.char == char:\n",
    "                    char_not_found = False\n",
    "                    node = child\n",
    "                    break\n",
    "        \n",
    "            if char_not_found:\n",
    "                return False\n",
    "        \n",
    "        return node.is_end\n",
    "    \n",
    "    def k_most_common(self, k):\n",
    "        \"\"\"\n",
    "        Finds k words inserted into the trie most often.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of most common words to be returned.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            List of tuples.\n",
    "            \n",
    "            Each tuple entry consists of the word and its frequency.\n",
    "            The entries are sorted by frequency.\n",
    "        \"\"\"\n",
    "        \n",
    "        sorted_count = {k: v for k, v in sorted(self.word_count.items(), key=lambda item: item[0])}\n",
    "        sorted_count = {k: v for k, v in sorted(sorted_count.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "        lst_common = []\n",
    "        \n",
    "        for key, value in sorted_count.items():\n",
    "            lst_common.append((key, value))\n",
    "            k -=1\n",
    "            if k == 0:\n",
    "                break\n",
    "        return lst_common\n",
    "        \n",
    "        \n",
    "    def autocomplete(self, prefix):\n",
    "        \"\"\"\n",
    "        Finds the most common word with the given prefix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        prefix : str\n",
    "            The word part to be “autocompleted”.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        str\n",
    "            The complete, most common word with the given prefix.\n",
    "            \n",
    "        Notes\n",
    "        ----------\n",
    "        The return value is equal to prefix if there is no valid word in the trie.\n",
    "        The return value is also equal to prefix if prefix is the most common word.\n",
    "        \"\"\"\n",
    "\n",
    "        words_with_pref = []\n",
    "        \n",
    "        #sorting the dictionary with counts again for this method\n",
    "        sorted_count = {k: v for k, v in sorted(self.word_count.items(), key=lambda item: item[0])}\n",
    "        sorted_count = {k: v for k, v in sorted(sorted_count.items(), key=lambda item: item[1], reverse = True)}\n",
    "        \n",
    "        sorted_words = sorted_count.keys()\n",
    "        \n",
    "        #picking words with the given prefix from the sorted list of words\n",
    "        for word in sorted_words:\n",
    "            if word.startswith(prefix):\n",
    "                words_with_pref.append(word)\n",
    "                \n",
    "        #returning the first and most popular word with the given prefix\n",
    "        the_word = words_with_pref[0]\n",
    "        return the_word    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "bad_chars = [';', ',', '.', '?', '!', '1', '2', '3', '4',\n",
    "             '5', '6', '7', '8', '9', '0', '_', '[', ']']\n",
    "\n",
    "SH_full = get('http://bit.ly/CS110-Shakespeare').text\n",
    "SH_just_text = ''.join(c for c in SH_full if c not in bad_chars)\n",
    "SH_without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in SH_just_text)\n",
    "SH_just_words = [word for word in SH_without_newlines.split(\" \") if word != \"\"]\n",
    "\n",
    "SH_trie = Trie(SH_just_words)\n",
    "\n",
    "assert SH_trie.autocomplete('hist') == 'history'\n",
    "assert SH_trie.autocomplete('en') == 'enter'\n",
    "assert SH_trie.autocomplete('cae') == 'caesar'\n",
    "assert SH_trie.autocomplete('gen') == 'gentleman'\n",
    "assert SH_trie.autocomplete('pen') == 'pen'\n",
    "assert SH_trie.autocomplete('tho') == 'thou'\n",
    "assert SH_trie.autocomplete('pent') == 'pentapolis'\n",
    "assert SH_trie.autocomplete('petr') == 'petruchio'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use the Ukrainian novel again. Since we saw \"так\" (or \"this way\"/\"yes\") among the most popular words in the novel and there were no more popular words that would start with \"та\" we can expect the autocomplete to return \"так\"  if we input \"та.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'так'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie = Trie(text)\n",
    "trie.autocomplete('та') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay, the output is the one that we expected. Out of curiousity let's see whether the code will be able to autocomplete numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1908'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie = Trie(text)\n",
    "trie.autocomplete('1') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works for numbers too and return year 1908 as the most popular number that starts with 1. Probably just the year of publication. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also test it for the very first text provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lantar'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie = Trie(wordbank)\n",
    "trie.autocomplete('l') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method I developed works! However, it is using the dictionary created as the tree is built that has all the words in the text as keys and the numbers of times those words are mentioned as values. I am using the whole list of words to find a specific subset that starts with a given prefix. Therefore, I have to go through all the words, which doesn't sound super efficient. The action of finding all the possible suggestion has the complexity of O(n) because of that. However, I can try utilizing the properties of the trie trees to improve this process at least a bit. We can traverse all the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    This class represents one node of a trie tree.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, char):\n",
    "        \n",
    "        self.char = char\n",
    "        self.children = []\n",
    "        self.children_str = []\n",
    "        self.is_end = False\n",
    "        self.counter = 0\n",
    "        \n",
    "        #setting the node initially to an empty string\n",
    "        self.str = \"\"\n",
    "        \n",
    "        \n",
    "class Trie:\n",
    "    \"\"\"\n",
    "    This class represents the entirety of a trie tree.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    insert(self, word)\n",
    "        Inserts a word into the trie, creating nodes as required.\n",
    "    lookup(self, word)\n",
    "        Determines whether a given word is present in the trie.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, word_list = None):\n",
    "        \"\"\"\n",
    "        Creates the Trie instance, inserts initial words if provided.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word_list : list\n",
    "            List of strings to be inserted into the trie upon creation.\n",
    "        \"\"\"\n",
    "              \n",
    "        self.root = Node(\"\")\n",
    "        self.word_count = {}\n",
    "        \n",
    "        if word_list:\n",
    "            for word in word_list:\n",
    "                word = word.lower()\n",
    "                self.insert(word)\n",
    "        \n",
    "    \n",
    "    def insert(self, word):\n",
    "        \"\"\"\n",
    "        Inserts a word into the trie, creating missing nodes on the go.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be inserted into the trie.\n",
    "        \"\"\"\n",
    "        \n",
    "        node = self.root \n",
    "        \n",
    "        for char in word:\n",
    "            found_in_child = False\n",
    "            for child_node in node.children:\n",
    "                if child_node.char == char:\n",
    "                    node = child_node\n",
    "                    found_in_child = True\n",
    "        \n",
    "            if not found_in_child:\n",
    "                new_node = Node(char)\n",
    "                node.children.append(new_node)\n",
    "                node.children_str.append(char)\n",
    "                node = new_node\n",
    "        \n",
    "        node.is_end = True\n",
    "        node.counter += 1\n",
    "        node.str = word\n",
    "        self.word_count[word] = node.counter\n",
    "\n",
    "        \n",
    "    def lookup(self, word):\n",
    "        \"\"\"\n",
    "        Determines whether a given word is present in the trie.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word : str\n",
    "            The word to be looked-up in the trie.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if the word is present in trie; False otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        node = self.root\n",
    "        \n",
    "        if not node.children:\n",
    "            return False\n",
    "        \n",
    "        word = word.lower()\n",
    "            \n",
    "        for char in word:\n",
    "            char_not_found = True\n",
    "            for child in node.children:\n",
    "                if child.char == char:\n",
    "                    char_not_found = False\n",
    "                    node = child\n",
    "                    break\n",
    "        \n",
    "            if char_not_found:\n",
    "                return False\n",
    "        \n",
    "        return node.is_end\n",
    "    \n",
    "    \n",
    "    def k_most_common(self, k):\n",
    "        \"\"\"\n",
    "        Finds k words inserted into the trie most often.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of most common words to be returned.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        list\n",
    "            List of tuples.\n",
    "            \n",
    "            Each tuple entry consists of the word and its frequency.\n",
    "            The entries are sorted by frequency.\n",
    "        \"\"\"\n",
    "        sorted_count = {k: v for k, v in sorted(self.word_count.items(), key=lambda item: item[0])}\n",
    "        sorted_count = {k: v for k, v in sorted(sorted_count.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "        lst_common = []\n",
    "        \n",
    "        for key, value in sorted_count.items():\n",
    "            lst_common.append((key, value))\n",
    "            k -=1\n",
    "            if k == 0:\n",
    "                break\n",
    "        return lst_common\n",
    "    \n",
    "    \n",
    "    def suggestions(self, node, suggestions = None, level=0):\n",
    "        '''\n",
    "        Finds the all the words that start with the given prefix in the text\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node instance\n",
    "            the ending node of a given prefix\n",
    "        \n",
    "        suggestions: list\n",
    "            the list of the words with the prefix that is recursively increased\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        suggestions: list\n",
    "            list with the suggestions\n",
    "        '''\n",
    "        \n",
    "        if suggestions is None:\n",
    "            suggestions = []\n",
    "            \n",
    "        #Recursively traverse the trie starting from where given prefix ends\n",
    "        ##and finding all the words that have the prefix\n",
    " \n",
    "        for a in node.children:\n",
    "            self.suggestions(a, suggestions, level+1)\n",
    "        \n",
    "        if node.is_end:\n",
    "            suggestions.append(node.str)\n",
    "            \n",
    "        #print(\" \"*level, suggestions)\n",
    "           \n",
    "        return suggestions\n",
    "        \n",
    "        \n",
    "    def autocomplete(self, prefix):\n",
    "        \"\"\"\n",
    "        Finds the most common word with the given prefix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        prefix : str\n",
    "            The word part to be “autocompleted”.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        str\n",
    "            The complete, most common word with the given prefix.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        #finding the node that is the end of the given prefix\n",
    "        node = self.root \n",
    "        for a in prefix:\n",
    "            if a not in node.children_str:\n",
    "                break\n",
    "            node = node.children[node.children_str.index(a)]\n",
    " \n",
    "        # If there are no letters to continue the prefix returning prefix itself\n",
    "        if not node.children:\n",
    "            return prefix\n",
    "        \n",
    "        #finding the list of all the possible suggestions using suggestions method\n",
    "        final = self.suggestions(node, suggestions = None)\n",
    "        #print(final)\n",
    "        #assigning the number of times the suggestions are mentioned to the words\n",
    "        final_count = {}\n",
    "        for suggestion in final:\n",
    "            final_count[suggestion] = self.word_count[suggestion]\n",
    "            \n",
    "        #print(f\"{final_count=}\")\n",
    "        \n",
    "        #sorting solely suggestions alphabetically and then by the count\n",
    "        sorted_count = {k: v for k, v in sorted(final_count.items(), key=lambda item: item[0])}\n",
    "        sorted_count = {k: v for k, v in sorted(sorted_count.items(), key=lambda item: item[1], reverse = True)}\n",
    "        \n",
    "        #extracting the list of suggestions from the sorted dictionary \n",
    "        sorted_suggestions = list(sorted_count.keys())\n",
    "        \n",
    "        #returning the most popular suggestion\n",
    "        #print(sorted_suggestions[0])\n",
    "        return sorted_suggestions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "bad_chars = [';', ',', '.', '?', '!', '1', '2', '3', '4',\n",
    "             '5', '6', '7', '8', '9', '0', '_', '[', ']']\n",
    "\n",
    "SH_full = get('http://bit.ly/CS110-Shakespeare').text\n",
    "SH_just_text = ''.join(c for c in SH_full if c not in bad_chars)\n",
    "SH_without_newlines = ''.join(c if (c not in ['\\n', '\\r', '\\t']) else \" \" for c in SH_just_text)\n",
    "SH_just_words = [word for word in SH_without_newlines.split(\" \") if word != \"\"]\n",
    "\n",
    "SH_trie = Trie(SH_just_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert SH_trie.autocomplete('hist') == 'history'\n",
    "assert SH_trie.autocomplete('en') == 'enter'\n",
    "assert SH_trie.autocomplete('cae') == 'caesar'\n",
    "assert SH_trie.autocomplete('gen') == 'gentleman'\n",
    "assert SH_trie.autocomplete('pen') == 'pen'\n",
    "assert SH_trie.autocomplete('tho') == 'thou'\n",
    "assert SH_trie.autocomplete('pent') == 'pentapolis'\n",
    "assert SH_trie.autocomplete('petr') == 'petruchio'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the same three tests with this code to check whether it works as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'так'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie = Trie(text)\n",
    "trie.autocomplete('та') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1908'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie = Trie(text)\n",
    "trie.autocomplete('1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lantar'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie = Trie(wordbank)\n",
    "trie.autocomplete('l') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6bdaaa",
   "metadata": {},
   "source": [
    "Yay! It works and returns the same suggestions as the previous a bit less efficient version. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
